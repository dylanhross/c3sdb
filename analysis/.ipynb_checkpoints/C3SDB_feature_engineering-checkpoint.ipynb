{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3S.db Feature Engineering\n",
    "### _Evaluation and optimization of the feature set to use in the prediction of CCS by ML on the data in the C3S.db (as of 2019/07/24)_\n",
    "#### Dylan H. Ross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup...\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from numpy import abs, mean, std, sqrt, sum, histogram, cumsum\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from C3SData.data import C3SD\n",
    "\n",
    "# set an initial pRNG seed, increment for each individual trial  \n",
    "pRNGs = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In the initial characterization of the Combined CCS Database (`C3S.db`), only a subset of the 50 total molecular descriptions (MDs) were found to contribute strongly to variance in the CCS. First, we will test the performance of models trained on the full set of MDs compared to those trained on the set of identifiers identified previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some utility functions for running and evaluating trials\n",
    "\n",
    "def metrics(model, data):\n",
    "    \"\"\"\n",
    "metrics\n",
    "    description:\n",
    "        computes a standard set of performance metrics using a trained model and dataset\n",
    "            * training and test set R-squared (R2)\n",
    "            * training and test set root mean squared error (RMSE)\n",
    "            * training and test set mean absolute error (MAE)\n",
    "            * cumulative error distribution at the 1, 3, 5, and 10% levels\n",
    "              for training and test set (CE135A)\n",
    "\"\"\"\n",
    "    summary = {}\n",
    "    for s in ['train', 'test']:\n",
    "        if s == 'train':\n",
    "            y = data.y_train_\n",
    "            y_pred = model.predict(data.X_train_ss_)\n",
    "        if s == 'test':\n",
    "            y = data.y_test_\n",
    "            y_pred = model.predict(data.X_test_ss_)\n",
    "            \n",
    "        # compute metrics\n",
    "        abs_y_err = abs(y_pred - y)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        mae = mean(abs_y_err)\n",
    "        rmse = sqrt(mean_squared_error(y, y_pred))\n",
    "        y_err_percent = 100. * abs_y_err / y\n",
    "        cum_err = cumsum(histogram(y_err_percent, [0, 1, 3, 5, 10, 100])[0])\n",
    "        cum_err = cum_err / sum(cum_err)\n",
    "        summary[s] = {'R2': r2, 'MAE': mae, 'RMSE': rmse, 'CE135A': cum_err[:4]}\n",
    "    return summary\n",
    "        \n",
    "\n",
    "def n_trials(model, mqn_indices, N, pRNGs, p_grid=None):\n",
    "    \"\"\"\n",
    "n_trials\n",
    "    description:\n",
    "        runs N trials training and evaluating a specified model with a specified dataset, each trial \n",
    "        using a different pRNG seed to establish different data splits. Returns the metrics from each trial.\n",
    "\"\"\"\n",
    "    trial_metrics = []\n",
    "    for i in range(N):\n",
    "        print('trial {:3d} of {:3d} ...'.format(i + 1, N), end=' ')\n",
    "        pRNGs += 1\n",
    "        data = C3SD('C3S.db', seed=pRNGs)\n",
    "        data.featurize(mqn_indices=mqn_indices)\n",
    "        data.train_test_split('ccs')\n",
    "        data.center_and_scale()\n",
    "        \n",
    "        # if a parameter grid is provided, perform hyperparameter optimization, otherwise simply fit the\n",
    "        # data with the model directly\n",
    "        if p_grid:\n",
    "            gs = GridSearchCV(model, param_grid=p_grid, n_jobs=-1, cv=5, scoring='neg_mean_squared_error')\n",
    "            gs.fit(data.X_train_ss_, data.y_train_)\n",
    "            model_best = gs.best_estimator_\n",
    "        else:\n",
    "            model_best = model.fit(data.X_train_ss_, data.y_train_)\n",
    "        \n",
    "        trial_metrics.append(metrics(model_best, data))\n",
    "    \n",
    "        print('ok')\n",
    "    return trial_metrics\n",
    "\n",
    "\n",
    "def summary_figure(summary):\n",
    "    \"\"\"\n",
    "summary_figure\n",
    "    description:\n",
    "        produces a summary figure displaying the results from a trial\n",
    "\"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 3))\n",
    "    gs = GridSpec(1, 3, figure=fig, width_ratios=[1, 3, 6])\n",
    "    \n",
    "    # R-squared\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    rsq_trn, rsq_trn_sd = mean([_['train']['R2'] for _ in summary]), std([_['train']['R2'] for _ in summary])\n",
    "    rsq_tst, rsq_tst_sd = mean([_['test']['R2'] for _ in summary]), std([_['test']['R2'] for _ in summary])\n",
    "    ax1.bar([0.87, 1.13], [rsq_trn, rsq_tst], color=['b', 'r'], yerr=[rsq_trn_sd, rsq_tst_sd], width=0.25)\n",
    "    for d in ['top', 'right']:\n",
    "        ax1.spines[d].set_visible(False)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_ylabel(r'R$^2$')\n",
    "    ax1.set_ylim([0.95, 1.0])\n",
    "    \n",
    "    # MAE and RMSE\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "    mae_trn, mae_trn_sd = mean([_['train']['MAE'] for _ in summary]), std([_['train']['MAE'] for _ in summary])\n",
    "    mae_tst, mae_tst_sd = mean([_['test']['MAE'] for _ in summary]), std([_['test']['MAE'] for _ in summary])\n",
    "    mse_trn, mse_trn_sd = mean([_['train']['RMSE'] for _ in summary]), std([_['train']['RMSE'] for _ in summary])\n",
    "    mse_tst, mse_tst_sd = mean([_['test']['RMSE'] for _ in summary]), std([_['test']['RMSE'] for _ in summary])\n",
    "    ax2.bar([0.87, 1.13], [mae_trn, mae_tst], color=['b', 'r'], yerr=[mae_trn_sd, mae_tst_sd], width=0.25)\n",
    "    ax2.bar([1.87, 2.13], [mse_trn, mse_tst], color=['b', 'r'], yerr=[mse_trn_sd, mse_tst_sd], width=0.25)\n",
    "    for d in ['top', 'right']:\n",
    "        ax2.spines[d].set_visible(False)\n",
    "    ax2.set_xticks([1, 2])\n",
    "    ax2.set_xticklabels(['MAE', 'RMSE'])\n",
    "    ax2.set_ylabel(r'CCS (Ã…$^2$)')\n",
    "    \n",
    "    # CE135A\n",
    "    ax3 = fig.add_subplot(gs[2])\n",
    "    ce1_trn, ce1_trn_sd = mean([100. * _['train']['CE135A'][0] for _ in summary]), std([100. * _['train']['CE135A'][0] for _ in summary])\n",
    "    ce3_trn, ce3_trn_sd = mean([100. * _['train']['CE135A'][1] for _ in summary]), std([100. * _['train']['CE135A'][1] for _ in summary])\n",
    "    ce5_trn, ce5_trn_sd = mean([100. * _['train']['CE135A'][2] for _ in summary]), std([100. * _['train']['CE135A'][2] for _ in summary])\n",
    "    ceA_trn, ceA_trn_sd = mean([100. * _['train']['CE135A'][3] for _ in summary]), std([100. * _['train']['CE135A'][3] for _ in summary])\n",
    "    \n",
    "    ce1_tst, ce1_tst_sd = mean([100. * _['test']['CE135A'][0] for _ in summary]), std([100. * _['test']['CE135A'][0] for _ in summary])\n",
    "    ce3_tst, ce3_tst_sd = mean([100. * _['test']['CE135A'][1] for _ in summary]), std([100. * _['test']['CE135A'][1] for _ in summary])\n",
    "    ce5_tst, ce5_tst_sd = mean([100. * _['test']['CE135A'][2] for _ in summary]), std([100. * _['test']['CE135A'][2] for _ in summary])\n",
    "    ceA_tst, ceA_tst_sd = mean([100. * _['test']['CE135A'][3] for _ in summary]), std([100. * _['test']['CE135A'][3] for _ in summary])\n",
    "    \n",
    "    \n",
    "    ax3.bar([0.87, 1.13], [ce1_trn, ce1_tst], color=['b', 'r'], yerr=[ce1_trn_sd, ce1_tst_sd], width=0.25)\n",
    "    ax3.bar([1.87, 2.13], [ce3_trn, ce3_tst], color=['b', 'r'], yerr=[ce3_trn_sd, ce3_tst_sd], width=0.25)\n",
    "    ax3.bar([2.87, 3.13], [ce5_trn, ce5_tst], color=['b', 'r'], yerr=[ce1_trn_sd, ce1_tst_sd], width=0.25)\n",
    "    ax3.bar([3.87, 4.13], [ceA_trn, ceA_tst], color=['b', 'r'], yerr=[ce3_trn_sd, ce3_tst_sd], width=0.25)\n",
    "    \n",
    "    for d in ['top', 'right']:\n",
    "        ax3.spines[d].set_visible(False)\n",
    "    ax3.set_xticks([0.5, 1, 2, 3, 4])\n",
    "    ax3.set_xticklabels(['CE', '1%', '3%', '5%', '10%'])\n",
    "    ax3.set_ylabel('proportion (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test these two sets of MDs, examine three distinct types of ML model:\n",
    "* linear, without regularization (`LinearRegression`)\n",
    "* SVR with rbf kernel (`SVR`)\n",
    "* random forest (`RandomForestRegression`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "mqn_subset = [0, 9, 11, 12, 13, 15, 18, 19, 20, 21, 22, 25, 26, 27, 30]\n",
    "# perform 20 trials each\n",
    "N = 20\n",
    "\n",
    "# linear regression\n",
    "print('\\nlinear, all MDs')\n",
    "linear_all = n_trials(LinearRegression(), 'all', N, pRNGs)\n",
    "pRNGs += N\n",
    "print('\\nlinear, MD subset')\n",
    "linear_sub = n_trials(LinearRegression(), mqn_subset, N, pRNGs)\n",
    "\n",
    "# SVR with rbf kernel\n",
    "pRNGs += N\n",
    "svr_p_grid = {\n",
    "    'C': [0.1, 0.3, 0.5, 1, 3, 5, 10],\n",
    "    'gamma': [0.0005, 0.001, 0.003, 0.005, 0.01, 0.03, 0.05, 0.1]\n",
    "}\n",
    "print('\\nSVR, all MDs')\n",
    "svr_all = n_trials(SVR(cache_size=1024, tol=5e-4), 'all', N, pRNGs, p_grid=svr_p_grid)\n",
    "pRNGs += N\n",
    "print('\\nSVR, MD subset')\n",
    "svr_sub = n_trials(SVR(cache_size=1024, tol=5e-4), mqn_subset, N, pRNGs, p_grid=svr_p_grid)\n",
    "\n",
    "# random forest\n",
    "pRNGs += N\n",
    "forest_p_grid = {\n",
    "    'max_depth': [2, 4, 6, 8],\n",
    "    'bootstrap': [True, False], \n",
    "    'min_samples_leaf': [0.256, 0.128, 0.064, 0.032, 0.016, 0.008, 0.004, 0.002, 0.001],\n",
    "    'n_estimators': [8, 16, 32, 64, 128]\n",
    "}\n",
    "print('\\nrandom forest, all MDs')\n",
    "forest_all = n_trials(RandomForestRegressor(), 'all', N, pRNGs, p_grid=forest_p_grid)\n",
    "pRNGs += N\n",
    "print('\\nrandom forest, MD subset')\n",
    "forest_sub = n_trials(RandomForestRegressor(), mqn_subset, N, pRNGs, p_grid=forest_p_grid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
